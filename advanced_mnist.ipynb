{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "advanced_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOy6mJpzWguWjJ8EWhN8mGN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uyan21/deepLearningStudy/blob/main/advanced_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEaUczp3Wkjx"
      },
      "source": [
        "# advaced mnist\r\n",
        "# Tensorflow 사이트에 mnist 전문가용 버전 코드 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8zdR2_TXIZJ"
      },
      "source": [
        "#1.tensorflow 임포트한다 (tf 계열 함수는 쓸모가 많으므로 일단 임포트하는거임)\r\n",
        "#2.레이어 임포트한다 뒤에는 레이어 종류 임포트 시킨다\r\n",
        "#3.Sequential 전문가용 버전은 시퀀셜 모델 안쓴다\r\n",
        "#4.one-hot encoding 함수용 함수\r\n",
        "#예) 10진수의 [8] 데이터라면 ->[0,0,0,0,0,0,0,0,1,0]\r\n",
        "#    8진수의 [5] 데이터라면 ->[0,0,0,0,0,1,0,0]\r\n",
        "#아웃풋 레이어는 이렇게 만들어놔야함 불문율"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIzgaDhfSAdz"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\r\n",
        "from tensorflow.keras import Model\r\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W15DQg_zYyuL"
      },
      "source": [
        "#mnist 데이터 받는다\r\n",
        "#255로 나누는것은 0~1사이 값으로 만드는 일명 정규화(normalization), 맵핑이라고도 함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45NbfL7TSH-N"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\r\n",
        "\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\r\n",
        "\r\n",
        "# 채널 차원을 추가합니다.\r\n",
        "x_train = x_train[..., tf.newaxis]\r\n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6tgJa0I-8CW",
        "outputId": "666c051b-117b-42de-f3cb-34f2f1bcaab2"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0YRiphpZRuD"
      },
      "source": [
        "#shuffle 10000은 섞는데 쓸 버퍼용량이 10000이라는 것(중요하지 않음)\r\n",
        "#batch가 32(32개씩 묶는 것임)\r\n",
        "#묶는 이유는 한꺼번에 32개 넣고 채점하고 넣고 채점 뒤에 함수 그렇게 해놈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BRhtyag_Cvs"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\r\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\r\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1cyez0cZtwW"
      },
      "source": [
        "#여기서는 레이어 모델을 클래스 상속을 하여 레이어를 쌓는다\r\n",
        "#인풋디멘션과 아웃풋 디멘션이 데이터 집어넣는 \r\n",
        "#즉시 알아서 첫 데이터 크기에 맞춰진다 -> 따로 설정할 필요 없으므로 편함\r\n",
        "#call 함수 이름 그대로 써야함 클래스 상속이기 때문임\r\n",
        "#(슈퍼클래스에 call이 이미 있어서 그대로 상속해서 \r\n",
        "#내부 채우는 것 이것을 오버라이딩이라 한다)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flxpdXPU_L8z"
      },
      "source": [
        "class MyModel(Model):\r\n",
        "  def __init__(self):\r\n",
        "    super(MyModel, self).__init__()\r\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\r\n",
        "    self.flatten = Flatten()\r\n",
        "    self.d1 = Dense(128, activation='relu')\r\n",
        "    self.d2 = Dense(10, activation='softmax')\r\n",
        "    \r\n",
        "  def call(self, x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.flatten(x)\r\n",
        "    x = self.d1(x)\r\n",
        "    return self.d2(x)\r\n",
        "\r\n",
        "model = MyModel()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZjelyVkbcfJ"
      },
      "source": [
        "#loss_object에 할당된 매서드가 뭐냐하면 loss_object(정답,예측 값)\r\n",
        "#넣고 일치율 계산용\r\n",
        "\r\n",
        "#optimizer 최적화 함수 종류 중 대표적인 adam (이거는 피드백 하는 거임, 말하면 김)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvDnA0F1_UHv",
        "outputId": "82f0fd0d-a6a2-43f5-f5dc-e7693c13d82f"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.Adam()\r\n",
        "print(loss_object)\r\n",
        "print(optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.losses.SparseCategoricalCrossentropy object at 0x7fce4d1934e0>\n",
            "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fce4d1932b0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgeJHTz9cZdq"
      },
      "source": [
        "#1,2줄 학습시 손실률과 1 batch 끝나고 정확성(채점할때 쓴다)\r\n",
        "\r\n",
        "#train_step 함수 정의\r\n",
        "#7줄 모델에서 예측 값 뱉고\r\n",
        "#8줄에서 정답하고 비교한다\r\n",
        "\r\n",
        "#그 밑에 gradientTape가 뭐냐면 저거는 미분용 함수인데 경사하강법을 쓰기 위해서 \r\n",
        "#(경사하강법으로 최적점을 찾아간다, 말하면 김)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1yGqJwf_0fd"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\r\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\r\n",
        "\r\n",
        "@tf.function\r\n",
        "def train_step(images, labels):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    predictions = model(images)\r\n",
        "    loss = loss_object(labels, predictions)\r\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "\r\n",
        "  train_loss(loss)\r\n",
        "  train_accuracy(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fenb0bgPdvkE"
      },
      "source": [
        "#테스트데이터로 학습모델 테스트할때 쓰는 함수 \r\n",
        "#위에 train_step에서 gradientTape 빠짐(피드 백,학습 할 필요 없으니까)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxfIL5mPOBzs"
      },
      "source": [
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\r\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\r\n",
        "\r\n",
        "@tf.function\r\n",
        "def test_step(images, labels):\r\n",
        "  predictions = model(images)\r\n",
        "  t_loss = loss_object(labels, predictions)\r\n",
        "\r\n",
        "  test_loss(t_loss)\r\n",
        "  test_accuracy(labels, predictions)\r\n",
        "  return test_accuracy.result()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H1CGAJvd9cs"
      },
      "source": [
        "#epochs 반복수 5\r\n",
        "#그 밑에 for문으로 batch 설정크기 (32개씩) 짤라서 넣는다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYWJt1lQ_-HQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8150ba-188b-4037-a66b-265f6d797d08"
      },
      "source": [
        "EPOCHS=5\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  for images, labels in train_ds:\r\n",
        "    train_step(images, labels)\r\n",
        "\r\n",
        "  for test_images, test_labels in test_ds:\r\n",
        "    test_step(test_images, test_labels)\r\n",
        "\r\n",
        "  template = '에포크: {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}'\r\n",
        "  print (template.format(epoch+1,\r\n",
        "                         train_loss.result(),\r\n",
        "                         train_accuracy.result()*100,\r\n",
        "                         test_loss.result(),\r\n",
        "                         test_accuracy.result()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "에포크: 1, 손실: 0.13814786076545715, 정확도: 95.88500213623047, 테스트 손실: 0.054303914308547974, 테스트 정확도: 98.29000091552734\n",
            "에포크: 2, 손실: 0.09018687158823013, 정확도: 97.28166198730469, 테스트 손실: 0.057121116667985916, 테스트 정확도: 98.18000030517578\n",
            "에포크: 3, 손실: 0.06752774864435196, 정확도: 97.96888732910156, 테스트 손실: 0.05558275803923607, 테스트 정확도: 98.22999572753906\n",
            "에포크: 4, 손실: 0.053904805332422256, 정확도: 98.37458038330078, 테스트 손실: 0.0565926656126976, 테스트 정확도: 98.26249694824219\n",
            "에포크: 5, 손실: 0.04475361481308937, 정확도: 98.64633178710938, 테스트 손실: 0.05684742331504822, 테스트 정확도: 98.3219985961914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSAJToGGeema"
      },
      "source": [
        "#이렇게 어려운 버전을 왜 쓰냐면\r\n",
        "#쉬운버전은 시퀀셜(일렬 레이어 모델) 밖에 설계가 안된다\r\n",
        "#이것보다 복잡한 레이어 모델을 만들려면 Sequential() 이거부터 시작해서 \r\n",
        "#model.add(레이어) 이런거 가지고는 안됨\r\n",
        "#(예 레이어가 상황에 따라 또 레이어를 만드는 유전 알고리즘,\r\n",
        "#분류후 각기 다른 레이어에 넣는 모델)"
      ]
    }
  ]
}